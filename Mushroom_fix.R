# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lf73fA1mENQJAKP1ru_UxNLpvT15S2qr
"""

install.packages("memisc")
install.packages("DMwR")
install.packages("caret")
install.packages("pROC")
install.packages("ROCR")
install.packages("dplyr")
install.packages("e1071")
install.packages("haven")
install.packages("ggplot2")
install.packages("scales")
install.packages("fastAdaboost")
install.packages("adabag")

library(memisc)
library(caret)
library(pROC)
library(ROCR)
library(dplyr)
library(e1071)
library(haven)
library(ggplot2)
library(scales)
library(fastAdaboost)
library(adabag)

mushroom <- read.csv("agaricus-lepiota.csv", header=FALSE)[,-17]
names(mushroom) <- c("Y",paste0("X0",1:9),paste0("X",10:21))
mushroom$Y <- ifelse(mushroom$Y=='e',"Edible","Poisonous")
for (i in 1:dim(mushroom)[2]) {
  mushroom[,i] <- factor(mushroom[,i])
}

s <- sample(2, dim(mushroom)[1], replace = T, prob = c(.8,.2))
train_data <- mushroom[s==1,]
test_data <- mushroom[s==2,]

set.seed(1234)
#ntree <- c(50,100, 200 ,300, 500)
#tree = 100

#Declaration metrics matrix
METRIC <- matrix(0,length(ntree),20)
colnames(METRIC) <- c("Accuracy","Kappa","AccuracyLower","AccuracyUpper","AccuracyNull","AccuracyPValue","McnemarPValue",
                      "Sensitivity","Specificity","Pos Pred Value","Neg Pred Value","Precision","Recall","F1","Prevalence",
                      "Detection Rate","Detection Prevalence","Balanced Accuracy","AUC","Trees")
CFM <- list()
nameX <- paste(ntree,"Trees")


#Adaboost
#i <- 0
#k <- 0
#for (ntrees in ntree) { #Looping with different trees
  #i <- i + 1
      #k <- k + 1
    #Adaboost function
    #model.adaboost <- adaboost(Y ~., data = train_data, nIter = ntrees)
    model <- boosting(Y ~., data = train_data, boos=TRUE, coeflearn = 'Breiman', mfinal = 50)
    
    #Y-prediction (label)
    pred <- predict(model, newdata = test_data , type = "class")
    
    #Y-prediction probability
    pred_prob <- predict(model, newdata = test_data, type = "prob")

    #pred <- ifelse(pred_prob > 0.5 , "Malignant" , "Benign")
    #pred <- as.factor(pred)
    #levels(pred) <- c(levels(pred))
    
    #Confusion Matrix
    cfmbc <- confusionMatrix(factor(pred$class, levels = c("Edible","Poisonous")), test_data$Y, positive = "Poisonous")
    
    #Save the metric value
    METRIC[] <- c(cfmbc$overall,cfmbc$byClass,auc(roc(test_data$Y,pred_prob$prob[,2])))
    #[k,]
    #ROC Value for ROC & AUC Graph
    #X <- prediction(pred_prob[,2],test_data$Y)
    #R <- performance(X,"tpr","fpr")
    
    #auc_graphF(R@y.values[[1]],R@x.values[[1]],METRIC[k,19],nameX[i],mtryX[j])
    
    #Save Confusion Matrix
    CFM[[paste(nameX[i])]] <- cfmbc$table

    
    #Erase the value for save memory
    #rf <- 0
   # cfmRF <- 0
    #pred <- 0
    #pred_prob <- 0
  #  X <- 0
    #R <- 0
  

#print(max(METRIC[,1]))

#Training Error Plot
c <- data.frame(train_data)
k <- ggplot () + 
  geom_line(data = c, aes(x=ntree, y=a)) +
  theme(plot.title = element_text(hjust = 0.5),
        
        panel.grid.major = element_line(color  = "lightgray",size = 0.25), 
        panel.background = element_rect(fill = "white", color = "black", size = 2)) + 
  labs(x = "Iteration", y = "LogLoss", 
       title = paste("Train logloss plot ")) + ylim(0,max(a))

METRIC

install.packages("tree")

t1 <-model$trees[[50]]
library(tree)
plot(t1)
text(t1,pretty=0)

cfmbc

a <- errorevol(model,train_data)

a

plot(a)

importanceplot(model)

importanceplot(model[10])

model$importance